---
title: Example output from simulations for MBNL1 where Va = 0
---

Perform 4df test of rs13069559 against 500k SNPs

```{r}
suppressPackageStartupMessages(suppressWarnings({
	library(dplyr)
	library(data.table)
	library(parallel)
	library(knitr)
}))
opts_chunk$set(cache=TRUE)
```


```{r}
a <- fread("../data/scratch/MBNL1_rs67903230_rs13069559/18778_disc_out")
names(a) <- c("snp1", "snp2", "df1", "df2", "fast_f8", "fast_f4")

b <- subset(a, df1 == 8)
b$fast_p4 <- pf(b$fast_f4, 4, b$df2, low=FALSE)
hist(b$fast_p4)
```

Replicate using native R statistical tests

```{r}
map <- fread("temp.map")
snplist <- c(map$V2[1], map$V2[-1][b$snp2])
write.table(snplist, file="snplist8df.txt", row=F, col=F, qu=F)
```


```{r engine="bash"}
episcan -De temp.ped temp.map ../data/scratch/MBNL1_rs67903230_rs13069559/rs13069559_merge_disc.egu
plink --file temp --extract snplist8df.txt --recode A --out temp
```

Read in the data, calculate the 4df F values

```{r}
ped <- fread("temp.raw", he=T)
fam <- fread("../data/scratch/MBNL1_rs67903230_rs13069559/18778_disc.fam")
mat <- ped[,-c(1:6)] %>% as.data.frame()
```

Allele frequency of rs13069559:

```{r}
sum(mat[,1], na.rm=T) / (2 * sum(!is.na(mat[,1])))
```

```{r}

out <- mclapply(2:ncol(mat), function(x)
{
	mod <- anova(
		lm(fam$V6 ~ as.factor(mat[,1]) + as.factor(mat[,x])),
		lm(fam$V6 ~ as.factor(mat[,1]) : as.factor(mat[,x]))
	)
	return(mod$F[2])

}, mc.cores=16)

b$r_f4 <- unlist(out)
b$r_p4 <- pf(b$r_f4, 4, b$df2, low=FALSE)
```

Distribution of p-values from R version of F test

```{r}
hist(b$r_p4)
```

Correlation between fast F test and R version

```{r}
cor(b$fast_f4, b$r_f4)
```

Correlation between fast and R versions of the p-values

```{r}
cor(b$fast_f4, b$r_f4)
```

Range of p-values

```{r}
range(b$fast_p4)
range(b$r_p4)
```

Lambda values

```{r}
median(b$fast_f4) / qchisq(0.5, 4) * 4
median(b$r_f4) / qchisq(0.5, 4) * 4
```

The fast version looks a bit more conservative. This is probably because when LD isn't accounted for between the two variants in the fast model, it slightly overestimates the additive variance and the residual non-additive variance is smaller.


## Other plots

Histograms of F values for fast and R versions

```{r}
hist(b$r_f4)
hist(b$fast_f4)
```

Is the rs13069559 more correlated with the rest of the genome than expected by chance?

Summary of rs13069559

```{r}
r_rs13069559 <- cor(mat[,1], mat[,-1])
median(r_rs13069559)
hist(r_rs13069559)
```

Choose some random snps, get median LD r of each SNP against all other SNPs

```{r}
set.seed(1)
snps <- sample(1:ncol(mat), 32, replace=FALSE)

rval <- mclapply(1:length(snps), function(x)
{
	r_rand <- cor(mat[,snps[x]], mat[,-snps[x]])
	return(median(r_rand))
}, mc.cores=16)
```

Plot median r values

```{r}
library(ggplot2)
o <- data.frame(what = c("rs13069559", rep("random", length(snps))), median_r = c(median(r_rs13069559), unlist(rval))) %>%
	arrange(median_r) %>%
	mutate(ord = 1:n()) 

ggplot(o, aes(x=ord, y=median_r)) +
geom_point(aes(colour=what))
```

Looks like the median LD across the genome of rs13069559 is pretty high.


## Restricting tests based on minimum cell count

Find pairs where minimum cell number is 5 or more, as was used in the original paper

```{r}
getcells <- function(mincount)
{
	cells <- mclapply(2:ncol(mat), function(x)
	{
		tab <- table(mat[,1], mat[,x])
		return(length(tab) == 9 & min(tab) >= mincount)
	}, mc.cores=16)

	cells <- unlist(cells)
	return(cells)
}

cells5 <- getcells(5)
cells3 <- getcells(3)
table(cells5)
table(cells3)
```

So, this drastically reduces the number of variants remaining in the analysis

```{r}
estlambda <- function(fval)
{
	median(fval) / qchisq(0.5, 4) * 4
}

estlambda(b$fast_f4)
estlambda(b$r_f4)
estlambda(b$fast_f4[cells3])
estlambda(b$r_f4[cells3])
estlambda(b$fast_f4[cells5])
estlambda(b$r_f4[cells5])
```
